<!DOCTYPE html>
<html lang="en">
<!-- 
  path: src/presentation/index.html
  description: System Gateway / Landing Page v21.1 - Thesis Candidate.
  
  ABSTRACT:
  The cinematic entry point to the Z-Realism Research Institute. This module 
  serves as the primary router, directing researchers to either the Static 
  Fusion (Img2Img) or Temporal Fusion (Video) laboratories.
  
  ARCHITECTURAL ROLE (Presentation Layer):
  Acts as the high-level orchestrator for the laboratory modules. It utilizes 
  modular component injection (Nav/Footer) to ensure architectural consistency 
  across the entire research ecosystem.

  author: Enrique Gonz√°lez Guti√©rrez <enrique.gonzalez.gutierrez@gmail.com>
-->
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Z-REALISM | Research Institute</title>

    <!-- FAVICON CONFIGURATION -->
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    
    <!-- Design System & Layout Orchestration -->
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/landing.css">
</head>
<body>
    <!-- Persistent Ambient Cyber-Grid Background -->
    <div class="grid-overlay"></div>

    <!-- 
      DYNAMIC NAVIGATION INJECTION: 
      The <nav> element is automatically injected by js/nav.js 
    injected at the top of the document flow.
    -->

    <!-- Hero Section: Neural Impact Area -->
    <header class="hero-section">
        <div class="hero-content">
            <span class="hero-tag">V21.1 NEURAL RESEARCH MODULE</span>
            <h1 class="hero-title">FROM INK<br>TO LIFE</h1>
            <p class="hero-desc">
                Z-Realism is an advanced research platform dedicated to the 
                photorealistic synthesis of characters from 2D source manifolds. 
                The institute explores how latent diffusion, structural priors, 
                and perceptual constraints can be orchestrated to transform 
                stylized representations into cinematic, high-fidelity realism.
            </p>
            <p class="hero-desc">
                By leveraging state-of-the-art Latent Diffusion pipelines and 
                rigorously controlled Temporal Consistency protocols, the system 
                translates <strong>Subject DNA</strong>‚Äîthe invariant visual identity 
                encoded in the source‚Äîinto coherent still imagery and motion-aware 
                sequences suitable for research, prototyping, and visual analysis.
            </p>
            <div class="hero-actions">
                <a href="image-lab.html" class="btn btn-primary">
                    ENTER STATIC LAB
                </a>
                <a href="video-lab.html" class="btn btn-primary" style="background: var(--accent-video); box-shadow: 0 4px 15px rgba(16, 185, 129, 0.3);">
                    ENTER TEMPORAL LAB
                </a>
            </div>
        </div>
    </header>

    <!-- Research Modules: Functional Gateways -->
    <main class="modules-container">
        <div class="modules-grid">
            
            <!-- Module 1: Static Fusion (Img2Img) -->
            <a href="image-lab.html" class="module-card">
                <div class="module-icon">üñºÔ∏è</div>
                <h3>Static Fusion</h3>
                <p>
                    The Static Fusion laboratory focuses on the synthesis of ultra 
                    high-resolution photorealistic stills from 2D character manifolds. 
                    It employs strict structural conditioning, depth-aware guidance, 
                    and chromatic stabilization techniques to preserve identity, 
                    anatomical coherence, and color fidelity during high-entropy 
                    denoising processes.
                </p>
                <p>
                    This module serves as the foundational stage of the research 
                    pipeline, producing identity-stable frames suitable for 
                    evaluation, dataset generation, or subsequent temporal extension.
                </p>
                <div class="module-link">LAUNCH STATIC MODULE &rarr;</div>
            </a>

            <!-- Module 2: Temporal Fusion (Img2Video) -->
            <a href="video-lab.html" class="module-card temporal">
                <div class="module-icon" style="filter: drop-shadow(0 0 15px var(--accent-video));">üé•</div>
                <h3>Temporal Fusion</h3>
                <p>
                    The Temporal Fusion laboratory extends static neural outputs 
                    into time-coherent cinematic sequences. It implements the 
                    AnimateDiff temporal engine augmented with frame-to-frame 
                    stabilization heuristics and motion-aware latent anchoring.
                </p>
                <p>
                    Sequential weight offloading and aggressive VRAM management 
                    enable high-resolution video synthesis on local, consumer-grade 
                    hardware, making temporal experimentation accessible without 
                    reliance on cloud-based compute clusters.
                </p>
                <div class="module-link">LAUNCH TEMPORAL MODULE &rarr;</div>
            </a>

            <!-- Module 3: Metadata Intelligence (DNA Analysis) -->
            <div class="module-card">
                <div class="module-icon">üß¨</div>
                <h3>Metadata Analysis</h3>
                <p>
                    The Metadata Analysis subsystem performs heuristic feature 
                    extraction on source manifolds and intermediate outputs. 
                    It identifies invariant visual traits, structural landmarks, 
                    and chromatic signatures that collectively define the 
                    subject‚Äôs visual DNA.
                </p>
                <p>
                    This intelligence layer sequences the extracted metadata into 
                    optimized stochastic parameters for the diffusion loop, enabling 
                    reproducibility, controlled variation, and identity preservation 
                    across both static and temporal synthesis stages.
                </p>
                <div class="module-link" style="color: var(--text-muted);">SYSTEM INTEGRATED</div>
            </div>

        </div>
    </main>

    <!-- 
      SHARED ARCHITECTURAL COMPONENTS 
      Injected at the end of the body to ensure DOM availability.
    -->
    <script src="js/nav.js"></script>
    <script src="js/footer.js"></script>
    <script src="js/cookie-consent.js"></script>

</body>
</html>
