<!DOCTYPE html>
<html lang="en">
<!-- 
  path: src/presentation/index.html
  description: System Gateway / Landing Page v21.1 - Thesis Candidate.
  
  ABSTRACT:
  The cinematic entry point to the Z-Realism Research Institute. This module 
  serves as the primary router, directing researchers to either the Static 
  Fusion (Img2Img) or Temporal Fusion (Video) laboratories.
  
  ARCHITECTURAL ROLE (Presentation Layer):
  Acts as the high-level orchestrator for the laboratory modules. It utilizes 
  modular component injection (Nav/Footer) to ensure architectural consistency 
  across the entire research ecosystem.

  RESEARCH CONTEXT:
  This landing environment is not merely a visual interface, but a conceptual 
  gateway into a structured experimentation framework focused on neural image 
  synthesis, controlled realism projection, and identity-preserving transformation 
  protocols. It represents the formal threshold between artistic abstraction and 
  computationally grounded photorealistic reconstruction.

  author: Enrique Gonz√°lez Guti√©rrez <enrique.gonzalez.gutierrez@gmail.com>
-->
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Z-REALISM | Research Institute</title>

    <!-- FAVICON CONFIGURATION -->
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    
    <!-- Design System & Layout Orchestration -->
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/landing.css">
</head>
<body>
    <!-- Persistent Ambient Cyber-Grid Background -->
    <div class="grid-overlay"></div>

    <!-- 
      DYNAMIC NAVIGATION INJECTION: 
      The <nav> element is automatically injected by js/nav.js 
    injected at the top of the document flow.
    -->

    <!-- Hero Section: Neural Impact Area -->
    <header class="hero-section">
        <div class="hero-content">
            <span class="hero-tag">V21.1 NEURAL RESEARCH MODULE</span>
            <h1 class="hero-title">FROM INK<br>TO LIFE</h1>
            <p class="hero-desc">
                Z-Realism is an advanced research platform dedicated to the 
                photorealistic synthesis of characters from 2D source manifolds. 
                The institute explores how latent diffusion, structural priors, 
                and perceptual constraints can be orchestrated to transform 
                stylized representations into cinematic, high-fidelity realism.
            </p>
            <p class="hero-desc">
                By leveraging state-of-the-art Latent Diffusion pipelines and 
                rigorously controlled Temporal Consistency protocols, the system 
                translates <strong>Subject DNA</strong>‚Äîthe invariant visual identity 
                encoded in the source‚Äîinto coherent still imagery and motion-aware 
                sequences suitable for research, prototyping, and visual analysis.
            </p>
            <p class="hero-desc">
                The platform operates under a modular experimentation philosophy, 
                where each synthesis stage is isolated, measurable, and reproducible. 
                Every output is treated as a data point within a broader continuum 
                of realism projection studies, allowing iterative refinement of 
                perceptual fidelity, lighting simulation accuracy, and anatomical 
                plausibility metrics.
            </p>
            <p class="hero-desc">
                Z-Realism does not aim to replace artistic intent; rather, it 
                augments it by introducing computational rigor into the transition 
                from symbolic illustration to physically plausible representation. 
                The result is a controlled bridge between imagination and neural 
                materialization.
            </p>
            <div class="hero-actions">
                <a href="image-lab.html" class="btn btn-primary">
                    ENTER STATIC LAB
                </a>
                <a href="video-lab.html" class="btn btn-primary" style="background: var(--accent-video); box-shadow: 0 4px 15px rgba(16, 185, 129, 0.3);">
                    ENTER TEMPORAL LAB
                </a>
            </div>
        </div>
    </header>

    <!-- Research Modules: Functional Gateways -->
    <main class="modules-container">
        <div class="modules-grid">
            
            <!-- Module 1: Static Fusion (Img2Img) -->
            <a href="image-lab.html" class="module-card">
                <div class="module-icon">üñºÔ∏è</div>
                <h3>Static Fusion</h3>
                <p>
                    The Static Fusion laboratory focuses on the synthesis of ultra 
                    high-resolution photorealistic stills from 2D character manifolds. 
                    It employs strict structural conditioning, depth-aware guidance, 
                    and chromatic stabilization techniques to preserve identity, 
                    anatomical coherence, and color fidelity during high-entropy 
                    denoising processes.
                </p>
                <p>
                    This module serves as the foundational stage of the research 
                    pipeline, producing identity-stable frames suitable for 
                    evaluation, dataset generation, or subsequent temporal extension.
                </p>
                <p>
                    Advanced prompt stratification and negative-conditioning 
                    matrices are applied to minimize semantic drift and mitigate 
                    latent hallucination artifacts. Cross-attention mapping is 
                    monitored to ensure that facial topology, proportional ratios, 
                    and texture distribution remain consistent with the extracted 
                    Subject DNA signature.
                </p>
                <p>
                    The laboratory is optimized for controlled experimentation, 
                    enabling researchers to compare sampling schedulers, CFG 
                    scaling strategies, and structural guidance weights in a 
                    reproducible and quantifiable manner.
                </p>
                <div class="module-link">LAUNCH STATIC MODULE &rarr;</div>
            </a>

            <!-- Module 2: Temporal Fusion (Img2Video) -->
            <a href="video-lab.html" class="module-card temporal">
                <div class="module-icon" style="filter: drop-shadow(0 0 15px var(--accent-video));">üé•</div>
                <h3>Temporal Fusion</h3>
                <p>
                    The Temporal Fusion laboratory extends static neural outputs 
                    into time-coherent cinematic sequences. It implements the 
                    AnimateDiff temporal engine augmented with frame-to-frame 
                    stabilization heuristics and motion-aware latent anchoring.
                </p>
                <p>
                    Sequential weight offloading and aggressive VRAM management 
                    enable high-resolution video synthesis on local, consumer-grade 
                    hardware, making temporal experimentation accessible without 
                    reliance on cloud-based compute clusters.
                </p>
                <p>
                    Motion vectors are constrained through adaptive noise injection 
                    and latent anchoring checkpoints, ensuring that identity features 
                    remain stable across micro-expressions, camera shifts, and 
                    simulated environmental lighting changes.
                </p>
                <p>
                    Temporal entropy is continuously evaluated to reduce flicker, 
                    geometry distortion, and chromatic instability. The result is 
                    a coherent, cinematic-grade output sequence that preserves 
                    both narrative continuity and biometric consistency.
                </p>
                <div class="module-link">LAUNCH TEMPORAL MODULE &rarr;</div>
            </a>

            <!-- Module 3: Metadata Intelligence (DNA Analysis) -->
            <div class="module-card">
                <div class="module-icon">üß¨</div>
                <h3>Metadata Analysis</h3>
                <p>
                    The Metadata Analysis subsystem performs heuristic feature 
                    extraction on source manifolds and intermediate outputs. 
                    It identifies invariant visual traits, structural landmarks, 
                    and chromatic signatures that collectively define the 
                    subject‚Äôs visual DNA.
                </p>
                <p>
                    This intelligence layer sequences the extracted metadata into 
                    optimized stochastic parameters for the diffusion loop, enabling 
                    reproducibility, controlled variation, and identity preservation 
                    across both static and temporal synthesis stages.
                </p>
                <p>
                    By correlating pixel-space observations with latent-space 
                    embeddings, the subsystem constructs a structured identity 
                    profile that can be re-injected into subsequent generations 
                    as a stabilization prior.
                </p>
                <p>
                    Over time, this metadata-driven architecture enables the 
                    creation of reusable identity templates, facilitating 
                    longitudinal experimentation and comparative realism studies 
                    across multiple synthesis cycles.
                </p>
                <div class="module-link" style="color: var(--text-muted);">SYSTEM INTEGRATED</div>
            </div>

        </div>
    </main>

    <!-- 
      SHARED ARCHITECTURAL COMPONENTS 
      Injected at the end of the body to ensure DOM availability.
    -->
    <script src="js/nav.js"></script>
    <script src="js/footer.js"></script>
    <script src="js/cookie-consent.js"></script>

</body>
</html>
